{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa17d52a-900a-4688-a0de-c2af702cdaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "581e964b-54c8-4412-9c73-c0f20a4097aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-preprocessing\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\berra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras-preprocessing) (1.26.4)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\berra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras-preprocessing) (1.16.0)\n",
      "Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Installing collected packages: keras-preprocessing\n",
      "Successfully installed keras-preprocessing-1.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1233fdfe-32c8-4812-9068-bef760f5fed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras_preprocessing.image import img_to_array\n",
    "from keras_preprocessing.image import load_img\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from flask import Flask, render_template, request\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import cv2\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d312b25b-7d5f-4be6-93af-424e8f085fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b725a97e-90e4-401d-8887-964dd34c4e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Chemin vers le dossier contenant les documents administratifs\n",
    "dossier_documents = r\"C:\\Users\\berra\\Desktop\\Stage\\Data\"\n",
    "\n",
    "# Liste des fichiers dans le dossier\n",
    "fichiers = os.listdir(dossier_documents)\n",
    "\n",
    "# Boucle à travers les fichiers\n",
    "for fichier in fichiers:\n",
    "    # Charger l'image\n",
    "    chemin_image = os.path.join(dossier_documents, fichier)\n",
    "    image = cv2.imread(chemin_image)\n",
    "\n",
    "    # Convertir l'image en niveaux de gris\n",
    "    image_grise = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Afficher l'image originale\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Image originale : \" + fichier)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Afficher l'image en niveaux de gris\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(image_grise, cmap='gray')\n",
    "    plt.title(\"Image en niveaux de gris : \" + fichier)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0c6756-9346-4b72-ae77-f1c6d137d93c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Chemin vers le dossier contenant les documents administratifs\n",
    "dossier_documents = r\"C:\\Users\\berra\\Desktop\\Stage\\Data\"\n",
    "\n",
    "# Liste des fichiers dans le dossier\n",
    "fichiers = os.listdir(dossier_documents)\n",
    "\n",
    "# Paramètres pour la détection des contours\n",
    "seuil_bas = 20\n",
    "seuil_haut = 150\n",
    "\n",
    "# Paramètres pour l'analyse des régions\n",
    "aire_minimale_contour = 500  # Aire minimale pour considérer un contour\n",
    "aire_minimale_signature = 2000  # Aire minimale pour considérer une signature\n",
    "\n",
    "# Boucle à travers les fichiers\n",
    "for fichier in fichiers:\n",
    "    # Charger l'image\n",
    "    chemin_image = os.path.join(dossier_documents, fichier)\n",
    "    image = cv2.imread(chemin_image)\n",
    "\n",
    "    # Convertir l'image en niveaux de gris\n",
    "    image_grise = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Appliquer un filtre de Sobel pour détecter les gradients\n",
    "    gradient_x = cv2.Sobel(image_grise, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    gradient_y = cv2.Sobel(image_grise, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    gradient_magnitude = np.sqrt(gradient_x**2 + gradient_y**2)\n",
    "    gradient_magnitude = np.uint8(255 * gradient_magnitude / np.max(gradient_magnitude))\n",
    "\n",
    "    # Seuillage adaptatif pour binariser l'image des gradients\n",
    "    _, image_binarisee = cv2.threshold(gradient_magnitude, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Appliquer une transformation morphologique pour supprimer le bruit\n",
    "    element_structurant = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    image_morpho = cv2.morphologyEx(image_binarisee, cv2.MORPH_CLOSE, element_structurant)\n",
    "\n",
    "    # Trouver les contours dans l'image\n",
    "    contours, _ = cv2.findContours(image_morpho, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Analyser les contours pour détecter les cachets et les signatures\n",
    "    for contour in contours:\n",
    "        aire = cv2.contourArea(contour)\n",
    "        if aire > aire_minimale_contour:\n",
    "            # Approximer le contour pour obtenir une forme plus simple\n",
    "            epsilon = 0.02 * cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "            x, y, w, h = cv2.boundingRect(approx)\n",
    "\n",
    "            # Filtrer les contours en fonction de leur taille et de leur forme\n",
    "            if aire > aire_minimale_signature:\n",
    "                # Dessiner un rectangle autour de la signature détectée\n",
    "                cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            else:\n",
    "                # Dessiner un rectangle autour du cachet détecté\n",
    "                cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "    # Afficher l'image avec les zones détectées\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Zones détectées : \" + fichier)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b86ebbe-88a5-459b-9c2c-c5c0d15e84f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Chemin vers le dossier contenant les documents administratifs\n",
    "dossier_documents = r\"C:\\Users\\berra\\Desktop\\Stage\\Data\"\n",
    "\n",
    "# Liste des fichiers dans le dossier\n",
    "fichiers = os.listdir(dossier_documents)\n",
    "\n",
    "# Paramètres pour la détection des contours\n",
    "seuil_bas = 30\n",
    "seuil_haut = 150\n",
    "\n",
    "# Paramètres pour l'analyse des régions\n",
    "aire_minimale_contour = 1000  # Aire minimale pour considérer un contour\n",
    "\n",
    "# Boucle à travers les fichiers\n",
    "for fichier in fichiers:\n",
    "    # Charger l'image\n",
    "    chemin_image = os.path.join(dossier_documents, fichier)\n",
    "    image = cv2.imread(chemin_image)\n",
    "\n",
    "    # Convertir l'image en niveaux de gris\n",
    "    image_grise = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Appliquer un filtre de Sobel pour détecter les gradients\n",
    "    gradient_x = cv2.Sobel(image_grise, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    gradient_y = cv2.Sobel(image_grise, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    gradient_magnitude = np.sqrt(gradient_x**2 + gradient_y**2)\n",
    "    gradient_magnitude = np.uint8(255 * gradient_magnitude / np.max(gradient_magnitude))\n",
    "\n",
    "    # Seuillage adaptatif pour binariser l'image des gradients\n",
    "    _, image_binarisee = cv2.threshold(gradient_magnitude, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Appliquer une transformation morphologique pour supprimer le bruit\n",
    "    element_structurant = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "    image_morpho = cv2.morphologyEx(image_binarisee, cv2.MORPH_CLOSE, element_structurant)\n",
    "\n",
    "    # Trouver les contours dans l'image\n",
    "    contours, _ = cv2.findContours(image_morpho, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Analyser les contours pour détecter les cachets et les signatures\n",
    "    for contour in contours:\n",
    "        aire = cv2.contourArea(contour)\n",
    "        if aire > aire_minimale_contour:\n",
    "            # Approximer le contour pour obtenir une forme plus simple\n",
    "            epsilon = 0.02 * cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "            x, y, w, h = cv2.boundingRect(approx)\n",
    "\n",
    "            # Filtrer les contours en fonction de leur taille et de leur forme\n",
    "            if w > 0.5 * h and w < 2 * h:\n",
    "                # Dessiner un rectangle autour de la zone détectée\n",
    "                cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Afficher l'image avec les zones détectées\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Zones détectées : \" + fichier)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60ee0a2-eb89-4aee-9438-cfef33c38402",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65b35db6-e03d-4a66-8887-dc9150edb8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de la zone: 4633200\n",
      "Rapport hauteur/largeur de la zone: 0.6993006993006993\n",
      "Caractéristiques HOG de la zone: [0.40652095 0.26965014 0.40652095 ... 0.10398196 0.09138939 0.06189567]\n",
      "Taille de la zone: 4673498\n",
      "Rapport hauteur/largeur de la zone: 0.6575393848462115\n",
      "Caractéristiques HOG de la zone: [0.44645777 0.34910054 0.44645777 ... 0.35454395 0.39201724 0.11911629]\n",
      "Taille de la zone: 4056570\n",
      "Rapport hauteur/largeur de la zone: 0.6670721816707218\n",
      "Caractéristiques HOG de la zone: [0.42054459 0.42054459 0.42054459 ... 0.41053073 0.41053073 0.06278537]\n",
      "Taille de la zone: 4129310\n",
      "Rapport hauteur/largeur de la zone: 0.685132382892057\n",
      "Caractéristiques HOG de la zone: [0.35581441 0.35581441 0.35581441 ... 0.39573184 0.39573184 0.13281486]\n",
      "Taille de la zone: 4092309\n",
      "Rapport hauteur/largeur de la zone: 0.7086974615064503\n",
      "Caractéristiques HOG de la zone: [0.40770566 0.40770566 0.40770566 ... 0.11013248 0.48702874 0.05191695]\n",
      "Taille de la zone: 3794040\n",
      "Rapport hauteur/largeur de la zone: 1.445679012345679\n",
      "Caractéristiques HOG de la zone: [0.37280101 0.32575827 0.37280101 ... 0.2820317  0.44232237 0.20393916]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "\n",
    "# Chemins d'accès vers les images\n",
    "chemins_images = [\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image1.jpg\",\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image2.jpg\",\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image3.jpg\",\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image4.jpg\",\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image5.jpg\",\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image6.jpg\"\n",
    "]\n",
    "\n",
    "# Fonction pour extraire les caractéristiques d'une zone\n",
    "def extraire_caracteristiques(image, zone):\n",
    "    # Convertir la zone en niveaux de gris\n",
    "    zone_grise = cv2.cvtColor(zone, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculer la taille de la zone\n",
    "    taille_zone = zone.shape[0] * zone.shape[1]\n",
    "    # Calculer le rapport hauteur/largeur de la zone\n",
    "    rapport_hauteur_largeur = zone.shape[0] / zone.shape[1]\n",
    "    # Calculer les caractéristiques HOG de la zone\n",
    "    hog_features, _ = hog(zone_grise, orientations=8, pixels_per_cell=(16, 16),\n",
    "                          cells_per_block=(1, 1), visualize=True, block_norm='L2-Hys')\n",
    "    return taille_zone, rapport_hauteur_largeur, hog_features\n",
    "\n",
    "# Boucle à travers les images\n",
    "for chemin_image in chemins_images:\n",
    "    # Charger l'image\n",
    "    image = cv2.imread(chemin_image)\n",
    "    # Convertir l'image en niveaux de gris\n",
    "    image_grise = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Trouver les contours dans l'image\n",
    "    contours, _ = cv2.findContours(image_grise, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Analyser les contours\n",
    "    for contour in contours:\n",
    "        # Extraire les coordonnées du rectangle englobant du contour\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        # Extraire la zone de l'image\n",
    "        zone = image[y:y+h, x:x+w]\n",
    "        # Extraire les caractéristiques de la zone\n",
    "        taille_zone, rapport_hauteur_largeur, hog_features = extraire_caracteristiques(image, zone)\n",
    "        # Afficher les caractéristiques extraites\n",
    "        print(\"Taille de la zone:\", taille_zone)\n",
    "        print(\"Rapport hauteur/largeur de la zone:\", rapport_hauteur_largeur)\n",
    "        print(\"Caractéristiques HOG de la zone:\", hog_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d76e71-8463-4157-b776-e3e6f6e59cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Chemins d'accès vers les images\n",
    "chemins_images = [\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image1.jpg\",\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image2.jpg\",\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image3.jpg\",\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image4.jpg\",\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image5.jpg\",\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image6.jpg\"\n",
    "]\n",
    "\n",
    "# Fonction pour extraire les caractéristiques d'une zone\n",
    "def extraire_caracteristiques(image, zone):\n",
    "    # Convertir la zone en niveaux de gris\n",
    "    zone_grise = cv2.cvtColor(zone, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculer la taille de la zone\n",
    "    taille_zone = zone.shape[0] * zone.shape[1]\n",
    "    # Calculer le rapport hauteur/largeur de la zone\n",
    "    rapport_hauteur_largeur = zone.shape[0] / zone.shape[1]\n",
    "    # Calculer les caractéristiques HOG de la zone\n",
    "    hog_features = np.ravel(cv2.HOGDescriptor().compute(zone_grise))\n",
    "    return taille_zone, rapport_hauteur_largeur, hog_features\n",
    "\n",
    "# Fonction pour extraire toutes les caractéristiques de toutes les zones détectées dans une image\n",
    "def extraire_toutes_caracteristiques(image):\n",
    "    # Convertir l'image en niveaux de gris\n",
    "    image_grise = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Trouver les contours dans l'image\n",
    "    contours, _ = cv2.findContours(image_grise, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Initialiser une liste pour stocker toutes les caractéristiques\n",
    "    toutes_caracteristiques = []\n",
    "    # Analyser les contours\n",
    "    for contour in contours:\n",
    "        # Extraire les coordonnées du rectangle englobant du contour\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        # Extraire la zone de l'image\n",
    "        zone = image[y:y+h, x:x+w]\n",
    "        # Extraire les caractéristiques de la zone\n",
    "        taille_zone, rapport_hauteur_largeur, hog_features = extraire_caracteristiques(image, zone)\n",
    "        # Ajouter les caractéristiques à la liste\n",
    "        toutes_caracteristiques.append([taille_zone, rapport_hauteur_largeur] + list(hog_features))\n",
    "    return toutes_caracteristiques\n",
    "\n",
    "# Extraire toutes les caractéristiques de toutes les zones détectées dans toutes les images\n",
    "toutes_caracteristiques = []\n",
    "for chemin_image in chemins_images:\n",
    "    # Charger l'image\n",
    "    image = cv2.imread(chemin_image)\n",
    "    # Extraire les caractéristiques de l'image\n",
    "    caracteristiques_image = extraire_toutes_caracteristiques(image)\n",
    "    # Ajouter les caractéristiques de l'image à la liste globale\n",
    "    toutes_caracteristiques.extend(caracteristiques_image)\n",
    "\n",
    "# Convertir la liste de caractéristiques en tableau numpy\n",
    "toutes_caracteristiques = np.array(toutes_caracteristiques)\n",
    "\n",
    "# Appliquer le clustering avec k-means\n",
    "nb_clusters = 3  # Nombre de clusters à former\n",
    "kmeans = KMeans(n_clusters=nb_clusters)\n",
    "kmeans.fit(toutes_caracteristiques)\n",
    "\n",
    "# Obtenir les étiquettes de cluster pour toutes les caractéristiques\n",
    "etiquettes_clusters = kmeans.predict(toutes_caracteristiques)\n",
    "\n",
    "# Afficher les étiquettes de cluster\n",
    "print(\"Étiquettes de cluster pour toutes les caractéristiques:\")\n",
    "print(etiquettes_clusters)\n",
    "\n",
    "# Afficher le nombre de zones détectées dans chaque cluster\n",
    "for i in range(nb_clusters):\n",
    "    nb_zones_cluster = np.sum(etiquettes_clusters == i)\n",
    "    print(\"Nombre de zones dans le cluster\", i, \":\", nb_zones_cluster)\n",
    "\n",
    "# Visualiser les clusters (à adapter en fonction de vos besoins)\n",
    "# Vous pouvez utiliser matplotlib pour afficher les zones détectées dans chaque cluster\n",
    "# Par exemple, vous pouvez afficher les zones détectées dans chaque cluster en utilisant différentes couleurs\n",
    "# Veuillez indiquer si vous souhaitez une démonstration de visualisation des clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7432b182-34f5-41c9-adfd-599c5843c809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "\n",
    "# Chemins d'accès vers les images\n",
    "chemins_images = [\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image1.jpg\",\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image2.jpg\",\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image3.jpg\",\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image4.jpg\",\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image5.jpg\",\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image6.jpg\"\n",
    "]\n",
    "\n",
    "# Fonction pour extraire les caractéristiques d'une zone\n",
    "def extraire_caracteristiques(image, zone):\n",
    "    # Convertir la zone en niveaux de gris\n",
    "    zone_grise = cv2.cvtColor(zone, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculer la taille de la zone\n",
    "    taille_zone = zone.shape[0] * zone.shape[1]\n",
    "    # Calculer le rapport hauteur/largeur de la zone\n",
    "    rapport_hauteur_largeur = zone.shape[0] / zone.shape[1]\n",
    "    # Calculer les caractéristiques HOG de la zone\n",
    "    hog_features, _ = hog(zone_grise, orientations=8, pixels_per_cell=(16, 16),\n",
    "                          cells_per_block=(1, 1), visualize=True, block_norm='L2-Hys')\n",
    "    return taille_zone, rapport_hauteur_largeur, hog_features\n",
    "\n",
    "# Boucle à travers les images\n",
    "for chemin_image in chemins_images:\n",
    "    # Charger l'image\n",
    "    image = cv2.imread(chemin_image)\n",
    "    # Convertir l'image en niveaux de gris\n",
    "    image_grise = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Trouver les contours dans l'image\n",
    "    contours, _ = cv2.findContours(image_grise, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Analyser les contours\n",
    "    for contour in contours:\n",
    "        # Extraire les coordonnées du rectangle englobant du contour\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        # Extraire la zone de l'image\n",
    "        zone = image[y:y+h, x:x+w]\n",
    "        # Extraire les caractéristiques de la zone\n",
    "        taille_zone, rapport_hauteur_largeur, hog_features = extraire_caracteristiques(image, zone)\n",
    "        # Afficher les caractéristiques extraites\n",
    "        print(\"Taille de la zone:\", taille_zone)\n",
    "        print(\"Rapport hauteur/largeur de la zone:\", rapport_hauteur_largeur)\n",
    "        print(\"Caractéristiques HOG de la zone:\", hog_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0700adb-b67e-4cc9-85fc-4681a6231b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Chemins d'accès vers les images\n",
    "chemins_images = [\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image1.jpg\",\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image2.jpg\",\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image3.jpg\",\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image4.jpg\",\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image5.jpg\",\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image6.jpg\"\n",
    "]\n",
    "\n",
    "# Fonction pour extraire les caractéristiques d'une zone\n",
    "def extraire_caracteristiques(image, zone):\n",
    "    # Convertir la zone en niveaux de gris\n",
    "    zone_grise = cv2.cvtColor(zone, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculer la taille de la zone\n",
    "    taille_zone = zone.shape[0] * zone.shape[1]\n",
    "    # Calculer le rapport hauteur/largeur de la zone\n",
    "    rapport_hauteur_largeur = zone.shape[0] / zone.shape[1]\n",
    "    # Calculer les caractéristiques HOG de la zone\n",
    "    hog_features = np.ravel(cv2.HOGDescriptor().compute(zone_grise))\n",
    "    return taille_zone, rapport_hauteur_largeur, hog_features\n",
    "\n",
    "# Charger et traiter les images une par une\n",
    "toutes_caracteristiques = []\n",
    "for chemin_image in chemins_images:\n",
    "    # Charger l'image\n",
    "    image = cv2.imread(chemin_image)\n",
    "    # Convertir l'image en niveaux de gris\n",
    "    image_grise = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Trouver les contours dans l'image\n",
    "    contours, _ = cv2.findContours(image_grise, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Analyser les contours et extraire les caractéristiques\n",
    "    for contour in contours:\n",
    "        # Extraire les coordonnées du rectangle englobant du contour\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        # Extraire la zone de l'image\n",
    "        zone = image[y:y+h, x:x+w]\n",
    "        # Extraire les caractéristiques de la zone\n",
    "        taille_zone, rapport_hauteur_largeur, hog_features = extraire_caracteristiques(image, zone)\n",
    "        # Ajouter les caractéristiques à la liste globale\n",
    "        toutes_caracteristiques.append([taille_zone, rapport_hauteur_largeur] + list(hog_features))\n",
    "\n",
    "# Convertir la liste de caractéristiques en tableau numpy\n",
    "toutes_caracteristiques = np.array(toutes_caracteristiques)\n",
    "\n",
    "# Appliquer le clustering avec k-means\n",
    "nb_clusters = 3  # Nombre de clusters à former\n",
    "kmeans = KMeans(n_clusters=nb_clusters)\n",
    "kmeans.fit(toutes_caracteristiques)\n",
    "\n",
    "# Obtenir les étiquettes de cluster pour toutes les caractéristiques\n",
    "etiquettes_clusters = kmeans.predict(toutes_caracteristiques)\n",
    "\n",
    "# Afficher les étiquettes de cluster\n",
    "print(\"Étiquettes de cluster pour toutes les caractéristiques:\")\n",
    "print(etiquettes_clusters)\n",
    "\n",
    "# Afficher le nombre de zones détectées dans chaque cluster\n",
    "for i in range(nb_clusters):\n",
    "    nb_zones_cluster = np.sum(etiquettes_clusters == i)\n",
    "    print(\"Nombre de zones dans le cluster\", i, \":\", nb_zones_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624182f9-78cd-4457-a570-617197717136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Chemins d'accès vers les images\n",
    "chemins_images = [\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image1.jpg\",\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image2.jpg\",\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image3.jpg\",\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image4.jpg\",\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image5.jpg\",\n",
    "    r\"C:\\Users\\berra\\Desktop\\Stage\\Data\\image6.jpg\"\n",
    "]\n",
    "\n",
    "# Fonction pour extraire les caractéristiques d'une zone\n",
    "def extraire_caracteristiques(image, zone):\n",
    "    # Convertir la zone en niveaux de gris\n",
    "    zone_grise = cv2.cvtColor(zone, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculer la taille de la zone\n",
    "    taille_zone = zone.shape[0] * zone.shape[1]\n",
    "    # Calculer le rapport hauteur/largeur de la zone\n",
    "    rapport_hauteur_largeur = zone.shape[0] / zone.shape[1]\n",
    "    # Calculer les caractéristiques HOG de la zone\n",
    "    hog_features = np.ravel(cv2.HOGDescriptor().compute(zone_grise))\n",
    "    return taille_zone, rapport_hauteur_largeur, hog_features\n",
    "\n",
    "# Charger les images, extraire un échantillon aléatoire des caractéristiques et les stocker dans une liste\n",
    "toutes_caracteristiques = []\n",
    "nb_zones_echantillon = 100  # Nombre de zones à sélectionner dans chaque image\n",
    "np.random.seed(42)  # Fixer la graine aléatoire pour la reproductibilité\n",
    "for chemin_image in chemins_images:\n",
    "    # Charger l'image\n",
    "    image = cv2.imread(chemin_image)\n",
    "    # Convertir l'image en niveaux de gris\n",
    "    image_grise = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Trouver les contours dans l'image\n",
    "    contours, _ = cv2.findContours(image_grise, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Aplatir la liste de contours\n",
    "    contours_aplatis = [contour.squeeze() for sublist in contours for contour in sublist]\n",
    "    # Vérifier s'il y a des contours détectés\n",
    "    if len(contours_aplatis) > 0:\n",
    "        # Générer des index aléatoires\n",
    "        indices_aleatoires = np.random.randint(0, len(contours_aplatis), size=nb_zones_echantillon)\n",
    "        # Extraire les zones correspondantes aux index aléatoires\n",
    "        zones_echantillon = [contours_aplatis[i] for i in indices_aleatoires]\n",
    "        for contour in zones_echantillon:\n",
    "            # Vérifier si le contour contient suffisamment de points\n",
    "            if len(contour) >= 4:\n",
    "                # Extraire les coordonnées du rectangle englobant du contour\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                # Extraire la zone de l'image\n",
    "                zone = image[y:y+h, x:x+w]\n",
    "                # Extraire les caractéristiques de la zone\n",
    "                taille_zone, rapport_hauteur_largeur, hog_features = extraire_caracteristiques(image, zone)\n",
    "                # Ajouter les caractéristiques à la liste\n",
    "                toutes_caracteristiques.append([taille_zone, rapport_hauteur_largeur] + list(hog_features))\n",
    "\n",
    "# Convertir la liste de caractéristiques en tableau numpy\n",
    "toutes_caracteristiques = np.array(toutes_caracteristiques)\n",
    "\n",
    "# Vérifier si des caractéristiques ont été extraites avant d'ajuster le modèle de clustering\n",
    "if len(toutes_caracteristiques) > 0:\n",
    "    # Appliquer le clustering avec k-means\n",
    "    nb_clusters = 3  # Nombre de clusters à former\n",
    "    kmeans = KMeans(n_clusters=nb_clusters)\n",
    "    kmeans.fit(toutes_caracteristiques)\n",
    "\n",
    "    # Obtenir les étiquettes de cluster pour toutes les caractéristiques\n",
    "    etiquettes_clusters = kmeans.predict(toutes_caracteristiques)\n",
    "\n",
    "    # Afficher les étiquettes de cluster\n",
    "    print(\"Étiquettes de cluster pour toutes les caractéristiques:\")\n",
    "    print(etiquettes_clusters)\n",
    "\n",
    "    # Afficher le nombre de zones détectées dans chaque cluster\n",
    "    for i in range(nb_clusters):\n",
    "        nb_zones_cluster = np.sum(etiquettes_clusters == i)\n",
    "        print(\"Nombre de zones dans le cluster\", i, \":\", nb_zones_cluster)\n",
    "else:\n",
    "    print(\"Aucune caractéristique n'a été extraite.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
